{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"Copy of hw1_dictionary-based_tokenization_to_student.ipynb","provenance":[{"file_id":"1vB0n4NP0BRVPueJB1ICQt_uTvZclaXDz","timestamp":1610990750520},{"file_id":"1VBE3DFY6pZEk-sR2kuuq7VYqjfI7pDgV","timestamp":1610628767964}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"7EdbVSmE87En"},"source":["# HW1: Dictionary-based Tokenization \n"]},{"cell_type":"markdown","metadata":{"id":"pJJLm1Ub87Et"},"source":["In this exercise, you are to implement a dictionary-based word segmentation algorithm. There are two Python functions that you need to complete: \n","<br>\n","* maximal_matching\n","* backtrack\n","</br>\n","\n","Also, you have to find how to use word_tokenize() in PythaiNLP along with customer_dict by yourselves."]},{"cell_type":"markdown","metadata":{"id":"DF5Pme7CK3YF"},"source":["## Part1) Your Maximal Matching with Your Dictionary"]},{"cell_type":"markdown","metadata":{"id":"xzs0R06q87Et"},"source":["### Create a toy dictionary to test the algorithm\n","\n","This is based on the example shown in the lecture. \n","You will tokenize the following text string: \"ไปหามเหสี!\"\n","The toy dictoionary provided in this exercise includes all the charaters, syllables, and words that appear that the text string."]},{"cell_type":"code","metadata":{"id":"pq3W4p3z87Ev","executionInfo":{"status":"ok","timestamp":1611162476120,"user_tz":-420,"elapsed":853,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}}},"source":["thai_vocab = [\"ไ\",\"ป\",\"ห\",\"า\",\"ม\",\"เ\",\"ห\",\"ส\",\"ี\",\"ไป\",\"หา\",\"หาม\",\"เห\",\"สี\",\"มเหสี\",\"!\"]"],"execution_count":95,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZornooGF87Ew"},"source":["### Maximal matching \n","Complete the maximal matching  function below to tokenize the input text\n"]},{"cell_type":"code","metadata":{"id":"Ao4d2E3387Ew","executionInfo":{"status":"ok","timestamp":1611162530076,"user_tz":-420,"elapsed":815,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}}},"source":["from math import inf #infinity\n","def maximal_matching(c):\n","    #Initialize an empty 2D list\n","    d  =[[None]*len(c) for _ in range(len(c))]\n","    \n","    ####FILL CODE HERE####\n","    for i in range(len(d)):\n","      word = c[i]\n","      for j in range(i, len(d)):\n","        if i == 0 and j == 0 : d[i][j] = 1\n","        elif i == 0 and word in thai_vocab: d[i][j] = 1\n","        elif i != 0 and word in thai_vocab:\n","          min = inf\n","          for k in range(i):\n","            if d[k][i-1] < min : min = d[k][i-1]\n","          d[i][j] = 1 + min\n","        else: d[i][j] = inf\n","        word = word + c[j+1] if j < len(d)-1 else word\n","            \n","        \n","    ######################\n","    \n","    return d"],"execution_count":99,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7vBXfjM87Ew"},"source":["### Backtracking\n","Complete the backtracking function below to find the tokenzied words.\n","It should return a list containing a pair of the beginning position and the ending position of each word.\n","In this example, it should return: \n","<br>\n","[(0, 1),(2, 3),(4, 8),(9, 9)]\n","<br> \n","#### Each pair contains the position of each word as follows:\n","(0, 1) ไป\n","<br>\n","(2, 3) หา\n","<br>\n","(4, 8) มเหสี\n","<br>\n","(9, 9) !\n"]},{"cell_type":"code","metadata":{"id":"SxNFf1IE87Ex","executionInfo":{"status":"ok","timestamp":1611162477327,"user_tz":-420,"elapsed":646,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}}},"source":["def backtrack(d):\n","    eow = len(d)-1 # End of Word position\n","    word_pos = [] # Word position\n","    ####FILL CODE HERE####\n","    row = eow\n","    col = eow\n","    while col > -1:\n","      min = inf\n","      # if col == -1:\n","      #   row = -1\n","      #  find min row in col\n","      for i in range(row, -1, -1):\n","        if d[i][col] < min:\n","          min = d[i][col]\n","          row = i\n","      for j in range(col, -1, -1):\n","        if out[row][j] == None or j == 0:\n","          end_pos = col\n","          start_pos = j + 1 if j != 0 else 0\n","          word_pos.append((start_pos, end_pos))\n","          col = start_pos\n","          break\n","      row -= 1\n","      col -= 1\n","\n","      \n","\n","    ######################\n","    word_pos.reverse()\n","    return word_pos\n"],"execution_count":97,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0MJkKsh87Ex"},"source":["### Test your maximal matching algorithm on a toy dictionary\n","\n","Expected output:\n","\n","[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","<br>\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","<br>\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","<br>\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","<br>\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","<br>\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","<br>\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","<br>\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","<br>\n","[None, None, None, None, None, None, None, None, None, 4] !\n","<br>"]},{"cell_type":"code","metadata":{"id":"tsmVQIKS87Ey","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611162534347,"user_tz":-420,"elapsed":826,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"ca2f28bc-0d8b-488d-ffb6-e937b323bd46"},"source":["input_text = \"ไปหามเหสี!\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"],"execution_count":100,"outputs":[{"output_type":"stream","text":["[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","[None, None, None, None, None, None, None, None, None, 4] !\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IVhCMM4d87Ey"},"source":["### Test your backtracking algorithm on a toy dictionary\n","Expected output:\n","<br>\n","ไป|หา|มเหสี|!"]},{"cell_type":"code","metadata":{"id":"6Hurbm1f87Ey","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611162538867,"user_tz":-420,"elapsed":999,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"9913bf18-f3d1-464b-8d46-0522d4bb9e9d"},"source":["def print_tokenized_text(d, input_text):\n","    tokenized_text=[]\n","    for pos in backtrack(d):\n","        #print(pos)\n","        tokenized_text.append(input_text[pos[0]:pos[1]+1])\n","\n","    print(\"|\".join(tokenized_text))\n","    \n","print_tokenized_text(out,input_text)"],"execution_count":101,"outputs":[{"output_type":"stream","text":["ไป|หา|มเหสี|!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"57rP9cTU87Ez"},"source":["## Part2) Your Maximal Matching with Real Dictionary"]},{"cell_type":"markdown","metadata":{"id":"V306h7AG87Ez"},"source":["For UNIX-based OS users, the following cell will download a dictionary (it's just a list of thai words). Alternatively, you can download it from this link: https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"EFVR9LO187Ez","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611161370242,"user_tz":-420,"elapsed":3072,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"abaa42eb-6db7-4818-8615-59660e3d7a41"},"source":["!wget https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"],"execution_count":75,"outputs":[{"output_type":"stream","text":["--2021-01-20 16:49:28--  https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1521600 (1.5M) [text/plain]\n","Saving to: ‘words_th.txt.1’\n","\n","words_th.txt.1      100%[===================>]   1.45M  --.-KB/s    in 0.08s   \n","\n","2021-01-20 16:49:29 (19.0 MB/s) - ‘words_th.txt.1’ saved [1521600/1521600]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nqIQzVgE87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611162546240,"user_tz":-420,"elapsed":907,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"26aeac3a-f236-4571-b7c1-ed1b400ea079"},"source":["with open(\"words_th.txt\",encoding='utf-8-sig') as f:\n","    thai_vocab = f.read().splitlines() \n","print(\"Vocab size:\", len(thai_vocab))\n","print(thai_vocab[:10])\n","\n","thai_vocab.extend([\"ๆ\",\"!\"])"],"execution_count":102,"outputs":[{"output_type":"stream","text":["Vocab size: 62143\n","['ก ข ไม่กระดิกหู', 'ก.', 'ก.ค.', 'ก.ต.', 'ก.ป.ส.', 'ก.พ.', 'ก.พ.ด.', 'ก.ม.', 'ก.ย.', 'ก.ย']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kpjwzw1w87E0"},"source":["### The output of your maximal matching algoithm on a new dictionary\n","Expected output:\n","<br>\n","[1, 1, 100000, 1, 100000, 100000, 100000, 100000, 100000] ไ\n","<br>\n","[None, 2, 100000, 100000, 100000, 100000, 100000, 100000, 100000] ป\n","<br>\n","[None, None, 2, 2, 2, 100000, 100000, 100000, 100000] ห\n","<br>\n","[None, None, None, 100000, 100000, 100000, 100000, 100000, 100000] า\n","<br>\n","[None, None, None, None, 2, 100000, 100000, 100000, 2] ม\n","<br>\n","[None, None, None, None, None, 100000, 3, 100000, 100000] เ\n","<br>\n","[None, None, None, None, None, None, 100001, 100000, 100000] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4] ส\n","<br>\n","[None, None, None, None, None, None, None, None, None] ี"]},{"cell_type":"code","metadata":{"id":"lYD5ChIS87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611162548700,"user_tz":-420,"elapsed":922,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"294d3dbd-a77d-4e0c-976e-5f9a1e808fcc"},"source":["input_text = \"ไปหามเหสี\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"],"execution_count":103,"outputs":[{"output_type":"stream","text":["[1, 1, inf, 1, inf, inf, inf, inf, inf] ไ\n","[None, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, inf, 2, 2, inf, inf, inf, inf] ห\n","[None, None, None, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, inf, inf, inf, inf, 2] ม\n","[None, None, None, None, None, inf, 3, inf, inf] เ\n","[None, None, None, None, None, None, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, inf, 4] ส\n","[None, None, None, None, None, None, None, None, inf] ี\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BSqLuK7G87E0"},"source":["### Expected tokenized text\n","ไปหา|มเหสี"]},{"cell_type":"code","metadata":{"id":"TI077jmy87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611162563649,"user_tz":-420,"elapsed":1052,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"cbf73e64-4ce2-43a1-9921-b86f048d2707"},"source":["# print('ไปหา' in thai_vocab)\n","# print('มเหสี' in thai_vocab)\n","# print('ปปป' in thai_vocab)\n","print_tokenized_text(out,input_text)"],"execution_count":104,"outputs":[{"output_type":"stream","text":["ไปหา|มเหสี\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VLGgO8PrLSz6"},"source":["## Part3) Maximal Matching from PythaiNLP"]},{"cell_type":"markdown","metadata":{"id":"LrZrzQoXLeUX"},"source":["### Default dictionary\n","\n","Study word_tokenize() from PythaiNLP in the link below.\n","\n","https://thainlp.org/pythainlp/docs/2.0/api/tokenize.html"]},{"cell_type":"code","metadata":{"id":"yXxPBOcNLXfm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611162906398,"user_tz":-420,"elapsed":27187,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"fc5e33ee-2523-4dfb-bd97-ad1f3c9213a8"},"source":["!pip install pythainlp\n","!pip install marisa_trie"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Collecting pythainlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/09/1215cb6f6ef0cfc9dbb427a961fda8a47c111955f782f659ca2d38c79adc/pythainlp-2.2.6-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 4.9MB/s \n","\u001b[?25hCollecting python-crfsuite>=0.9.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 48.7MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.23.0)\n","Collecting tinydb>=3.0\n","  Downloading https://files.pythonhosted.org/packages/e5/7e/85ee672ee60affd5b4461efa19f260cf7575f36b94fbd1f0825742639910/tinydb-4.3.0-py3-none-any.whl\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Installing collected packages: python-crfsuite, tinydb, pythainlp\n","Successfully installed pythainlp-2.2.6 python-crfsuite-0.9.7 tinydb-4.3.0\n","Collecting marisa_trie\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n","\u001b[K     |████████████████████████████████| 276kB 5.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: marisa-trie\n","  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862150 sha256=30d64c4b5e9a2bbaeb7f6c52bf6b477c3d2fb22be4a77a10f1f402364ee3f16d\n","  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n","Successfully built marisa-trie\n","Installing collected packages: marisa-trie\n","Successfully installed marisa-trie-0.7.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"goQE5gFUL4KO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611164948757,"user_tz":-420,"elapsed":908,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"b243d888-42fa-47ce-f42c-769972bcd53f"},"source":["from pythainlp.tokenize import word_tokenize, thai_words\n","text='นัดกินกันตอนไหนก็ได้ที่สามย่านมิตรทาวน์'\n","\n","####FILL CODE HERE####\n","word_tokenize(text, engine='newmm')\n","######################"],"execution_count":153,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่าน', 'มิตร', 'ทาวน์']"]},"metadata":{"tags":[]},"execution_count":153}]},{"cell_type":"markdown","metadata":{"id":"2SlX5cEBMHPd"},"source":["### Custom dictionary\n","\n","Add 'สามย่านมิตรทาวน์' into dictionary and then tokenize again"]},{"cell_type":"code","metadata":{"id":"b4V9TqFaMPAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611164950555,"user_tz":-420,"elapsed":1134,"user":{"displayName":"Siwakorn Boonmun","photoUrl":"","userId":"05970087592187803676"}},"outputId":"b54e86cf-c117-4e22-80eb-1bbb4583d5d0"},"source":["####FILL CODE HERE####\n","import marisa_trie\n","custom_dict = set(thai_words())\n","custom_dict.add('สามย่านมิตรทาวน์')\n","trie = marisa_trie.Trie(custom_dict)\n","word_tokenize(text, engine='newmm', custom_dict=trie)\n","######################"],"execution_count":154,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่านมิตรทาวน์']"]},"metadata":{"tags":[]},"execution_count":154}]},{"cell_type":"code","metadata":{"id":"uszHCli_6CJc"},"source":[""],"execution_count":null,"outputs":[]}]}